{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import abc\n",
    "import argparse\n",
    "import itertools\n",
    "import pathlib\n",
    "import multiprocessing as mp\n",
    "import typing\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('TkAgg')\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from frog_identity_recognition import utils\n",
    "\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import cv2\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--threshold\", default=0.5, type=float)\n",
    "parser.add_argument(\"--resize-width\", default=600, type=int)\n",
    "parser.add_argument(\"--resize-height\", default=None, type=typing.Optional[int])\n",
    "parser.add_argument(\"--matcher\", default=\"orb\", type=str)  # sift, orb, mse\n",
    "parser.add_argument(\"--lowe-ratio\", default=0.79, type=float)\n",
    "parser.add_argument(\"--mean-distance\", default=False, type=bool)\n",
    "parser.add_argument(\"--top-k-matches\", default=5, type=int)\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "if args.matcher == \"mse\" and not args.mean_distance:\n",
    "    raise RuntimeError(\"MSE cannot be used without mean_distance=True\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_roi(segmentation, bbox, image_path, resize_width=None, resize_height=None, image_cache=None):\n",
    "    box = np.asarray(bbox)\n",
    "\n",
    "    mask = np.asarray([segmentation])\n",
    "    seg_contour = np.reshape(mask, (int(mask.shape[-1] / 2), 2))\n",
    "\n",
    "    if image_cache and image_path in image_cache:\n",
    "        orginal_image = image_cache[image_path]\n",
    "    else:\n",
    "        orginal_image = cv2.imread(image_path)\n",
    "\n",
    "    # Resize processes\n",
    "    if resize_width or resize_height:\n",
    "        image = utils.image_resize(orginal_image, width=resize_width, height=resize_height)\n",
    "        seg_contour = utils.contour_resize(seg_contour, orginal_image, image)\n",
    "        box = utils.bbox_resize(box, orginal_image, image)\n",
    "\n",
    "    x, y, w, h = box\n",
    "\n",
    "    image_mask = np.zeros(image.shape[:2], dtype=\"uint8\")\n",
    "    cv2.polylines(image_mask, [seg_contour], True, 255, 1)\n",
    "\n",
    "    # find the external contours\n",
    "    contours = cv2.findContours(image_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "    cnt = contours[0]\n",
    "\n",
    "    # Fill image mask in the contour area\n",
    "    cv2.drawContours(image_mask, [cnt], 0, 255, -1)\n",
    "\n",
    "    # Mask out relevant area\n",
    "    roi = cv2.bitwise_and(image, image, mask=image_mask)\n",
    "\n",
    "    # Extract exactly the relevant bbox\n",
    "    roi = roi[y:y + h, x:x + w]\n",
    "\n",
    "    return roi\n",
    "\n",
    "\n",
    "def apply_grayscale_and_filter(img):\n",
    "    result = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    result = cv2.medianBlur(result, 1)\n",
    "    result = cv2.adaptiveThreshold(result, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 101, 1)\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class MSEMatcher():\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def detectAndCompute(self, image, *args, **kwargs):\n",
    "        return None, image\n",
    "\n",
    "    def match(self, image1, image2):\n",
    "        mse = ((image1 - image2)**2).mean(axis=None)\n",
    "        return mse\n",
    "\n",
    "class Matcher:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.lowe_ratio = args.lowe_ratio\n",
    "\n",
    "        if args.matcher == \"orb\":\n",
    "            self._detector = cv2.ORB_create()\n",
    "            self._matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "            self._matcher_fn = self._match_orb\n",
    "            self._draw_fn = self._draw_orb\n",
    "\n",
    "        elif args.matcher == \"sift\":\n",
    "            self._detector = cv2.SIFT_create()\n",
    "            self._matcher = cv2.BFMatcher()\n",
    "            self._matcher_fn = self._match_sift\n",
    "            self._draw_fn = self._draw_sift\n",
    "        elif args.matcher == \"mse\":\n",
    "            self._detector = MSEMatcher()\n",
    "            self._matcher = self._detector\n",
    "            self._matcher_fn = self._match_mse\n",
    "            self._draw_fn = self._draw_mse\n",
    "\n",
    "\n",
    "\n",
    "    def detect(self, image1, image2):\n",
    "        # finding key points and descriptors of both images using detectAndCompute() function\n",
    "        key_point1, descrip1 = self._detector.detectAndCompute(image1, None)\n",
    "        key_point2, descrip2 = self._detector.detectAndCompute(image2, None)\n",
    "\n",
    "        try:\n",
    "            list_of_matches, mean_distance = self._matcher_fn(descrip1, descrip2)\n",
    "        except Exception as e:\n",
    "            list_of_matches, mean_distance = [], 90000000\n",
    "\n",
    "        return len(list_of_matches), list_of_matches, mean_distance, key_point1, key_point2\n",
    "\n",
    "    def _match_mse(self, des1, des2):\n",
    "        distance = self._matcher(des1, des2)\n",
    "        return [], distance\n",
    "\n",
    "    def _match_sift(self, des1, des2):\n",
    "        matches = self._matcher.knnMatch(des1,des2,k=2)\n",
    "        good = []\n",
    "        for m,n in matches:\n",
    "            if m.distance < args.lowe_ratio*n.distance:\n",
    "                good.append([m])\n",
    "\n",
    "        average_distance = sum([x.distance for x in good]) / len(good)\n",
    "        return good, average_distance\n",
    "\n",
    "    def _match_orb(self, des1, des2):\n",
    "        # Match descriptors.\n",
    "        matches = self._matcher.match(des1,des2)\n",
    "\n",
    "        # Sort them in the order of their distance.\n",
    "        matches = list(sorted(matches, key = lambda x:x.distance))\n",
    "        matches = matches[:min(len(matches), args.top_k_matches)]\n",
    "\n",
    "        average_distance = sum([x.distance for x in matches]) / len(matches)\n",
    "\n",
    "\n",
    "        return matches, average_distance\n",
    "\n",
    "    def _draw_sift(self, img1, kp1, img2, kp2, matches):\n",
    "        return cv2.drawMatchesKnn(img1,kp1,img2,kp2,matches,None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "    def _draw_orb(self, img1, kp1, img2, kp2, matches):\n",
    "        return cv2.drawMatches(img1,kp1,img2,kp2,matches,None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "    def _draw_mse(self, img1, kp1, img2, kp2, matches):\n",
    "        return img1 - img2\n",
    "\n",
    "    def draw_matches(self, img1, kp1, img2, kp2, matches):\n",
    "        return self._draw_fn(img1, kp1, img2, kp2, matches)\n",
    "\n",
    "\n",
    "ds = load_dataset(\n",
    "    \"perara/pelophylax_lessonae\",\n",
    "    name=\"default\",\n",
    "    splits=[\"train\", \"test\"],\n",
    "    image_dir=\"./frog_photos\"\n",
    ")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    ### Step 1: Train Mask R-CNN manually labeled data\n",
    "    \"\"\"\n",
    "# TODO\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### Step 2: Annotate dataset with trained Mask R-CNN\n",
    "\"\"\"\n",
    "# TODO\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "### Step 3: Annotate dataset with trained Mask R-CNN\n",
    "\"\"\"\n",
    "# Image cache\n",
    "\"\"\"image_cache_path = pathlib.Path(\"image_cache.npz\")\n",
    "if not image_cache_path.exists():\n",
    "    np.save(\n",
    "        str(image_cache_path.absolute()),\n",
    "        {\n",
    "            sample[\"image_path\"]: cv2.imread(sample[\"image_path\"])\n",
    "            for sample in tqdm(ds[\"train\"], desc=\"Caching images as pickle file...\")\n",
    "        }\n",
    "    )\n",
    "\n",
    "image_cache = np.load(str(image_cache_path))\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset = list(ds[\"train\"])\n",
    "dataset = [x for x in dataset if \"spring\" in x[\"image_path\"]]\n",
    "#dataset = dataset[0:30]\n",
    "\n",
    "\n",
    "\n",
    "def _roi_processing(sample):\n",
    "    filename_base = pathlib.Path(sample[\"image_path\"]).stem\n",
    "    frog_id = filename_base.split(\"_\")[-1]\n",
    "\n",
    "\n",
    "    roi = extract_roi(\n",
    "        segmentation=sample[\"segmentation\"][0],\n",
    "        bbox=sample[\"bbox\"],\n",
    "        image_path=sample[\"image_path\"],\n",
    "        resize_width=args.resize_width,\n",
    "        resize_height=args.resize_height,\n",
    "        image_cache=None  # image_cache\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"filename\": filename_base,\n",
    "        \"frog_id\": frog_id,\n",
    "        \"roi\": roi\n",
    "    }\n",
    "\n",
    "with mp.Pool(processes=os.cpu_count()) as pool:\n",
    "    roi_ds = list(tqdm(pool.imap(_roi_processing,  dataset), total=len(dataset), desc=\"Loading images into memory and extracting ROI from mask.\"))\n",
    "\n",
    "\n",
    "# Maps integer ID to frog_id\n",
    "frog_ids = set([x[\"frog_id\"] for x in roi_ds])\n",
    "frog_ids_map = {frog_id: i for i, frog_id in enumerate(frog_ids)}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Apply grascale + blur filtering\n",
    "\"\"\"\n",
    "for item in roi_ds:\n",
    "    item[\"roi\"] = apply_grayscale_and_filter(item[\"roi\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _image_matcher(args):\n",
    "    matcher_name, sample1, sample2 = args\n",
    "\n",
    "    detector = Matcher()\n",
    "\n",
    "    s_name_1 = sample1[\"filename\"]\n",
    "    s_name_2 = sample2[\"filename\"]\n",
    "    s_frog_id_1 = sample1[\"frog_id\"]\n",
    "    s_frog_id_2 = sample2[\"frog_id\"]\n",
    "\n",
    "\n",
    "    num_matches, matches, mean_distance, kpt1, kpt2 = detector.detect(sample1[\"roi\"], sample2[\"roi\"])\n",
    "\n",
    "    return dict(\n",
    "        sample_1=s_name_1,\n",
    "        sample_2=s_name_2,\n",
    "        match_count=num_matches,\n",
    "        sample_1_id=s_frog_id_1,\n",
    "        sample_2_id=s_frog_id_2,\n",
    "        mean_distance=mean_distance\n",
    "    )\n",
    "\n",
    "\n",
    "with mp.Pool(processes=os.cpu_count()) as pool:\n",
    "    data_comb = list(itertools.combinations(roi_ds, r=2))\n",
    "    data_comb = [[args.matcher] + list(x) for x in data_comb]\n",
    "\n",
    "    mp_results: list = list(tqdm(pool.imap(_image_matcher,  data_comb), desc=\"Performing matching for all samples.\", total=len(data_comb)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "results = {}\n",
    "for res in tqdm(mp_results, desc=\"Transforming results from multiprocessing to map structure\"):\n",
    "\n",
    "    if res[\"sample_1\"] not in results:\n",
    "        results[res[\"sample_1\"]] = []\n",
    "    if res[\"sample_2\"] not in results:\n",
    "        results[res[\"sample_2\"]] = []\n",
    "\n",
    "    results[res[\"sample_1\"]].append((\n",
    "        (res[\"sample_2_id\"], res[\"match_count\"], res[\"sample_2\"], res[\"mean_distance\"])\n",
    "    ))\n",
    "    results[res[\"sample_2\"]].append((\n",
    "        (res[\"sample_1_id\"], res[\"match_count\"], res[\"sample_1\"], res[\"mean_distance\"])\n",
    "    ))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results2 = results.copy()\n",
    "# Sort matches and \"classify\" with the one having most matches.\n",
    "for k in tqdm(results.keys()):\n",
    "    if args.mean_distance:\n",
    "        results2[k] = sorted(results2[k], key=lambda x: x[3], reverse=False)[0]\n",
    "    else:\n",
    "        results2[k] = sorted(results2[k], key=lambda x: x[1], reverse=True)[0]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Print best matching data\n",
    "\"\"\"\n",
    "samples_dir = pathlib.Path(\"./match_samples\")\n",
    "samples_dir.mkdir(exist_ok=True)\n",
    "save_images = True\n",
    "\n",
    "if save_images:\n",
    "    for sample_1_name, (sample_2_id, match_count, sample_2_name, average_distance) in tqdm(results2.items()):\n",
    "\n",
    "        # Retrieve rois from roi_dataset\n",
    "        s_1, s_2 = list(filter(lambda x: x[\"filename\"] in [sample_1_name, sample_2_name], roi_ds))\n",
    "\n",
    "\n",
    "        s_name_1 = s_1[\"filename\"]\n",
    "        s_name_2 = s_2[\"filename\"]\n",
    "        s_frog_id_1 = s_1[\"frog_id\"]\n",
    "        s_frog_id_2 = s_2[\"frog_id\"]\n",
    "\n",
    "\n",
    "        # Matching\n",
    "        detector = Matcher()\n",
    "        num_matches, matches, mean_distance, kpt1, kpt2 = detector.detect(s_1[\"roi\"], s_2[\"roi\"])\n",
    "\n",
    "\n",
    "        actual_frog_id = sample_1_name.split(\"_\")[-1]\n",
    "        prediction_frog_id = sample_2_id\n",
    "\n",
    "        if actual_frog_id == prediction_frog_id:\n",
    "            image_save_path = samples_dir.joinpath(\"correct\")\n",
    "        else:\n",
    "            image_save_path = samples_dir.joinpath(\"incorrect\")\n",
    "\n",
    "        image_save_path.mkdir(exist_ok=True)\n",
    "\n",
    "        save_path = str(image_save_path.joinpath(f\"{s_name_1}-{s_name_2}_{s_frog_id_1}-{s_frog_id_2}.jpg\").absolute())\n",
    "\n",
    "        img3 = detector.draw_matches(s_1[\"roi\"], kpt1, s_2[\"roi\"], kpt2, matches)\n",
    "\n",
    "        cv2.imwrite(save_path, img3)\n",
    "\n",
    "else:\n",
    "    save_path = None\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "plt.clf()\n",
    "\"\"\"\n",
    "# Plot final results\n",
    "\"\"\"\n",
    "n_frog_individuals = len(frog_ids)\n",
    "cf_matrix = np.zeros((n_frog_individuals, n_frog_individuals), dtype=int)\n",
    "\n",
    "success_rate = 0.0\n",
    "for filename, prediction in tqdm(results2.items(), desc=\"Populating confusion matrix\"):\n",
    "    actual_frog_id = filename.split(\"_\")[-1]\n",
    "    prediction_frog_id = prediction[0]\n",
    "\n",
    "    if actual_frog_id == prediction_frog_id:\n",
    "        success_rate += 1.0\n",
    "\n",
    "print(success_rate / len(results2))\n",
    "\n",
    "\n",
    "\n",
    "    #cf_matrix[frog_ids_map[actual_frog_id]][frog_ids_map[prediction_frog_id[0]]] += 1\n",
    "\n",
    "#df = pd.DataFrame(cf_matrix, columns=frog_ids_map, index=frog_ids_map)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "heatmap_figure = sns.heatmap(df, annot=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "figure = heatmap_figure.get_figure()\n",
    "figure.savefig('svm_conf.png', dpi=400)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
