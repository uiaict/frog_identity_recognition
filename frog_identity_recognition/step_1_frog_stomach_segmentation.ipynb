{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/3bf863cc.pub\n",
    "#!apt-get update && apt install -y git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "#!pip install git+https://github.com/matterport/Mask_RCNN.git --upgrade\n",
    "!pip install git+https://github.com/mdrokz/Mask-RCNN-TF2.7.0-keras2.7.0.git --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy scipy Pillow cython matplotlib imgaug opencv-python datasets IPython[all]\n",
    "#!pip install scikit-image==0.16.2 keras==2.0.8 h5py==2.10.0\n",
    "#!pip install tensorflow-gpu==1.15.5'\n",
    "\n",
    "!pip install scikit-image==0.16.2\n",
    "!pip install tensorflow==2.7.0\n",
    "!pip install keras==2.7.0\n",
    "!pip install opencv-python\n",
    "!pip install h5py==2.10.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"]  = \"python\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import\n",
    "In order to train, we would need GPU power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "import pathlib\n",
    "from numpy import asarray\n",
    "import mrcnn.utils\n",
    "import mrcnn.config\n",
    "import mrcnn.model\n",
    "from mrcnn import visualize\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from mrcnn import utils\n",
    "import imgaug\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = pathlib.Path(\"weights\")\n",
    "WEIGHTS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "WEIGHTS_CHECKPOINT_PATH = WEIGHTS_PATH.joinpath(\"checkpoints\")\n",
    "WEIGHTS_CHECKPOINT_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "COCO_WEIGHTS = WEIGHTS_PATH.joinpath(\"mask_rcnn_coco.h5\")\n",
    "FROG_WEIGHTS = WEIGHTS_PATH.joinpath('mask_rcnn_frog.h5')\n",
    "\n",
    "\n",
    "CLASS_NAME = \"frog_stomach\"\n",
    "CLASS_NAMES = [CLASS_NAME, \"BG\"]\n",
    "FROG_IMAGES = \"./frog_photos\"\n",
    "FROG_DATASET = \"./pelophylax_lessonae\" \"\"#\"perara/pelophylax_lessonae\"\n",
    "\n",
    "\n",
    "WEIGHTS_CHECKPOINT_PATH.joinpath(CLASS_NAME).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download COCO weights if missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not COCO_WEIGHTS.exists():\n",
    "    utils.download_trained_weights(str(COCO_WEIGHTS.absolute()))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Configure dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mrcnn.model import DataGenerator\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "\n",
    "class FrogStomachDataset(mrcnn.utils.Dataset):\n",
    "\n",
    "    def load_dataset(self, images_dir: str, dataset_dir: str=None, is_train=True):\n",
    "        # Adds information (image ID, image path, and annotation file path) about each image in a dictionary.\n",
    "        self.add_class(\"dataset\", 1, CLASS_NAME)\n",
    "\n",
    "        images_dir_path = pathlib.Path(images_dir)\n",
    "        dataset_split = \"train\" if is_train else \"validation\"\n",
    "        ds = load_dataset(\n",
    "            FROG_DATASET,\n",
    "            name=\"default\",\n",
    "            splits=[dataset_split],\n",
    "            image_dir=images_dir_path,\n",
    "            dataset_dir=dataset_dir\n",
    "        )\n",
    "\n",
    "        for sample in ds[dataset_split]:\n",
    "            image_id = sample[\"image_id\"]\n",
    "            image_path = sample[\"image_path\"]\n",
    "            annotation = sample[\"segmentation\"]\n",
    "            width = sample[\"width\"]\n",
    "            height = sample[\"height\"]\n",
    "            category_id = sample[\"category_id\"]\n",
    "\n",
    "            self.add_image('dataset', image_id=image_id, path=image_path, annotation=annotation, width=width, height=height, category_id=category_id)\n",
    "\n",
    "    # Loads the binary masks for an image.\n",
    "    def load_mask(self, image_id):\n",
    "\n",
    "        image_info = self.image_info[image_id]\n",
    "        annotations = image_info['annotation']\n",
    "        width = image_info[\"width\"]\n",
    "        height = image_info[\"height\"]\n",
    "        category_id = image_info[\"category_id\"]\n",
    "        instance_masks = []\n",
    "        class_ids = []\n",
    "\n",
    "\n",
    "        mask = Image.new('1', (width, height))\n",
    "        mask_draw = ImageDraw.ImageDraw(mask, '1')\n",
    "        for segmentation in annotations:\n",
    "            try:\n",
    "                mask_draw.polygon(segmentation, fill=1)\n",
    "            except:\n",
    "                pass\n",
    "            bool_array = np.array(mask) > 0\n",
    "            instance_masks.append(bool_array)\n",
    "            class_ids.append(category_id)\n",
    "\n",
    "        mask = np.dstack(instance_masks)\n",
    "        class_ids = np.array(class_ids, dtype=np.int32)\n",
    "\n",
    "        return mask.astype(\"bool\"), asarray(class_ids, dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Training and Validation Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train\n",
    "train_dataset = FrogStomachDataset()\n",
    "train_dataset.load_dataset(\n",
    "    images_dir=str(FROG_IMAGES),\n",
    "    dataset_dir=str(FROG_DATASET),\n",
    "    is_train=True\n",
    ")\n",
    "train_dataset.prepare()\n",
    "\n",
    "val_dataset = FrogStomachDataset()\n",
    "val_dataset.load_dataset(\n",
    "    images_dir=str(FROG_IMAGES),\n",
    "    dataset_dir=str(FROG_DATASET),\n",
    "    is_train=False\n",
    ")\n",
    "val_dataset.prepare()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualize samples from Validation Set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = np.random.choice(val_dataset.image_ids, 1)\n",
    "for image_id in image_ids:\n",
    "    image = val_dataset.load_image(image_id)\n",
    "    mask, class_ids = val_dataset.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, val_dataset.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup Mask R-CNN - Training Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrogStomachConfig(mrcnn.config.Config):\n",
    "    NAME = CLASS_NAME\n",
    "    GPU_COUNT = 1\n",
    "    NUM_CLASSES =  1 + 1\n",
    "\n",
    "\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "\n",
    "    IMAGES_PER_GPU = 16\n",
    "    STEPS_PER_EPOCH = 100\n",
    "    IMAGE_MIN_DIM = 128\n",
    "    IMAGE_MAX_DIM = 128\n",
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "# Model Configuration\n",
    "frog_config = FrogStomachConfig()\n",
    "\n",
    "# Build the Mask R-CNN Model Architecture\n",
    "train_model = mrcnn.model.MaskRCNN(mode='training',\n",
    "                             model_dir=str(WEIGHTS_PATH.absolute()),\n",
    "                             config=frog_config)\n",
    "\n",
    "\"\"\"train_model.keras_model.add_metric(\n",
    "    tf.keras.metrics.MeanIoU(name=\"mean_io_u_1\",dtype=tf.float32,num_classes=2), name=\"metric_io_u\"\n",
    ")\"\"\"\n",
    "\n",
    "last_model = train_model.find_last()\n",
    "train_model.load_weights(filepath=last_model, by_name=True , exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "\"\"\"train_model.load_weights(filepath=str(COCO_WEIGHTS.absolute()),\n",
    "                         by_name=True,\n",
    "                         exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup Mask R-CNN - Inference Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class InferenceConfig(FrogStomachConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    USE_MINI_MASK = False\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "inference_model = mrcnn.model.MaskRCNN(mode=\"inference\",\n",
    "                             config=inference_config,\n",
    "                             model_dir=str(WEIGHTS_PATH.absolute()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frog_identity_recognition.callbacks import MeanAveragePrecisionCallback\n",
    "\n",
    "\"\"\"mean_average_precision_callback = MeanAveragePrecisionCallback(\n",
    "    train_model,\n",
    "    inference_model,\n",
    "    val_dataset,\n",
    "    calculate_map_at_every_X_epoch=1,\n",
    "    verbose=1\n",
    ")\"\"\"\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    train_model.train(train_dataset=train_dataset,\n",
    "                val_dataset=val_dataset,\n",
    "                learning_rate=frog_config.LEARNING_RATE,\n",
    "                custom_callbacks=[], # mean_average_precision_callback\n",
    "                epochs=EPOCHS,\n",
    "                layers='heads')\n",
    "    \"\"\"augmentation = imgaug.augmenters.Sometimes(0.5, [\n",
    "        imgaug.augmenters.Fliplr(0.5),\n",
    "        imgaug.augmenters.GaussianBlur(sigma=(0.0, 5.0))\n",
    "    ]),\"\"\"\n",
    "\n",
    "    train_model.keras_model.save_weights(str(FROG_WEIGHTS.absolute()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also\n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "train_model.train(train_dataset, val_dataset,\n",
    "            learning_rate=frog_config.LEARNING_RATE / 10,\n",
    "            epochs=int(EPOCHS / 2),\n",
    "            layers=\"all\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inference_model_path = inference_model.find_last()\n",
    "\n",
    "print(\"Loading weights from \", inference_model_path)\n",
    "inference_model.load_weights(inference_model_path, by_name=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "# Test on a random image\n",
    "image_id = random.choice(val_dataset.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    mrcnn.model.load_image_gt(val_dataset, inference_config, image_id)\n",
    "\n",
    "\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id,\n",
    "                            train_dataset.class_names, figsize=(8, 8))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from mrcnn.model import log\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "dataset = train_dataset\n",
    "config = inference_config\n",
    "\n",
    "image_id = random.choice(dataset.image_ids)\n",
    "\n",
    "image, image_meta, gt_class_id, gt_bbox, gt_mask = mrcnn.model.load_image_gt(dataset, config, image_id)\n",
    "\n",
    "print(image.shape)\n",
    "\n",
    "info = dataset.image_info[image_id]\n",
    "print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id,\n",
    "                                       dataset.image_reference(image_id)))\n",
    "\n",
    "# Run object detection\n",
    "results = inference_model.detect([image], verbose=1)\n",
    "\n",
    "# Display results\n",
    "r = results[0]\n",
    "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], dataset.class_names, r['scores'], title=\"Predictions\")\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "dataset = train_dataset\n",
    "\n",
    "# Must call before using the dataset\n",
    "dataset.prepare()\n",
    "\n",
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "import skimage.color\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def color_splash(image, mask):\n",
    "    \"\"\"Apply color splash effect.\n",
    "    image: RGB image [height, width, 3]\n",
    "    mask: instance segmentation mask [height, width, instance count]\n",
    "    Returns result image.\n",
    "    \"\"\"\n",
    "    # Make a grayscale copy of the image. The grayscale copy still\n",
    "    # has 3 RGB channels, though.\n",
    "    gray = skimage.color.gray2rgb(skimage.color.rgb2gray(image)) * 255\n",
    "    # We're treating all instances as one, so collapse the mask into one layer\n",
    "    mask = (np.sum(mask, -1, keepdims=True) >= 1)\n",
    "    # Copy color pixels from the original color image where mask is set\n",
    "    if mask.shape[0] > 0:\n",
    "        splash = np.where(mask, image, gray).astype(np.uint8)\n",
    "    else:\n",
    "        splash = gray\n",
    "    return splash\n",
    "\n",
    "def detect_and_color_splash(model, image=None):\n",
    "\n",
    "\n",
    "    #print(\"Running on {}\".format(args.image))\n",
    "    # Read image\n",
    "    #image = skimage.io.imread(args.image)\n",
    "    # Detect objects\n",
    "    r = model.detect([image], verbose=1)[0]\n",
    "    # Color splash\n",
    "    splash = color_splash(image, r['masks'])\n",
    "    # Save output\n",
    "    #file_name = \"splash_{:%Y%m%dT%H%M%S}.png\".format(datetime.datetime.now())\n",
    "    #skimage.io.imsave(file_name, splash)\n",
    "    return splash\n",
    "\n",
    "image_ids = np.random.choice(val_dataset.image_ids, 1)\n",
    "for image_id in image_ids:\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask = mrcnn.model.load_image_gt(val_dataset, config, image_id)\n",
    "\n",
    "    splash = detect_and_color_splash(inference_model, image)\n",
    "\n",
    "\n",
    "    plt.imshow(splash, interpolation='nearest')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
