{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"]  = \"python\"\n",
    "import mrcnn.visualize\n",
    "import mrcnn.config\n",
    "import mrcnn.model\n",
    "from datasets import load_dataset\n",
    "import warnings\n",
    "import cv2\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = pathlib.Path(\"weights\")\n",
    "WEIGHTS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "WEIGHTS_CHECKPOINT_PATH = WEIGHTS_PATH.joinpath(\"checkpoints\")\n",
    "WEIGHTS_CHECKPOINT_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "COCO_WEIGHTS = WEIGHTS_PATH.joinpath(\"mask_rcnn_coco.h5\")\n",
    "#FROG_WEIGHTS = list(WEIGHTS_CHECKPOINT_PATH.glob(\"*.h5\"))[-1]\n",
    "#FROG_WEIGHTS = WEIGHTS_PATH.joinpath(\"mask_rcnn_frog_students.h5\")\n",
    "\n",
    "\n",
    "CLASS_NAME = \"frog_stomach\"\n",
    "CLASS_NAMES = [\"BG\", CLASS_NAME]\n",
    "FROG_IMAGES = \"./frog_photos\"\n",
    "FROG_DATASET = \"./pelophylax_lessonae\" \"\"#\"perara/pelophylax_lessonae\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "from PIL import ImageDraw, Image\n",
    "import mrcnn.utils\n",
    "\n",
    "class FrogStomachDataset(mrcnn.utils.Dataset):\n",
    "\n",
    "    def load_dataset(self, images_dir: str, dataset_dir: str=None, is_train=True):\n",
    "        # Adds information (image ID, image path, and annotation file path) about each image in a dictionary.\n",
    "        self.add_class(\"dataset\", 1, CLASS_NAME)\n",
    "\n",
    "        images_dir_path = pathlib.Path(images_dir)\n",
    "        dataset_split = \"train\" if is_train else \"validation\"\n",
    "        ds = load_dataset(\n",
    "            FROG_DATASET,\n",
    "            name=\"default\",\n",
    "            splits=[dataset_split],\n",
    "            image_dir=images_dir_path,\n",
    "            dataset_dir=dataset_dir\n",
    "        )\n",
    "\n",
    "        for sample in ds[dataset_split]:\n",
    "            image_id = sample[\"image_id\"]\n",
    "            image_path = sample[\"image_path\"]\n",
    "            annotation = sample[\"segmentation\"]\n",
    "            width = sample[\"width\"]\n",
    "            height = sample[\"height\"]\n",
    "            category_id = sample[\"category_id\"]\n",
    "\n",
    "            self.add_image('dataset', image_id=image_id, path=image_path, annotation=annotation, width=width, height=height, category_id=category_id)\n",
    "\n",
    "    # Loads the binary masks for an image.\n",
    "    def load_mask(self, image_id):\n",
    "\n",
    "        image_info = self.image_info[image_id]\n",
    "        annotations = image_info['annotation']\n",
    "        width = image_info[\"width\"]\n",
    "        height = image_info[\"height\"]\n",
    "        category_id = image_info[\"category_id\"]\n",
    "        instance_masks = []\n",
    "        class_ids = []\n",
    "\n",
    "\n",
    "        mask = Image.new('1', (width, height))\n",
    "        mask_draw = ImageDraw.ImageDraw(mask, '1')\n",
    "        for segmentation in annotations:\n",
    "            try:\n",
    "                mask_draw.polygon(segmentation, fill=1)\n",
    "            except:\n",
    "                pass\n",
    "            bool_array = np.array(mask) > 0\n",
    "            instance_masks.append(bool_array)\n",
    "            class_ids.append(category_id)\n",
    "\n",
    "        mask = np.dstack(instance_masks)\n",
    "        class_ids = np.array(class_ids, dtype=np.int32)\n",
    "\n",
    "        return mask.astype(\"bool\"), asarray(class_ids, dtype='int32')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class FrogStomachConfig(mrcnn.config.Config):\n",
    "    NAME = CLASS_NAME\n",
    "    GPU_COUNT = 1\n",
    "    NUM_CLASSES =  1 + 1\n",
    "\n",
    "\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "\n",
    "    IMAGES_PER_GPU = 16\n",
    "    STEPS_PER_EPOCH = 100\n",
    "    IMAGE_MIN_DIM = 128\n",
    "    IMAGE_MAX_DIM = 128\n",
    "EPOCHS = 100\n",
    "class InferenceConfig(FrogStomachConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    USE_MINI_MASK = False\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = InferenceConfig()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    model_inference = mrcnn.model.MaskRCNN(mode=\"inference\",\n",
    "                                           config=config,\n",
    "                                           model_dir=WEIGHTS_PATH)\n",
    "\n",
    "\n",
    "\n",
    "    model_inference.load_weights(filepath=model_inference.find_last(),\n",
    "                                 by_name=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "val_dataset = FrogStomachDataset()\n",
    "val_dataset.load_dataset(\n",
    "    images_dir=str(FROG_IMAGES),\n",
    "    dataset_dir=str(FROG_DATASET),\n",
    "    is_train=False\n",
    ")\n",
    "val_dataset.prepare()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from mrcnn import visualize\n",
    "import random\n",
    "\n",
    "dataset = val_dataset\n",
    "config = config\n",
    "\n",
    "image_id = random.choice(dataset.image_ids)\n",
    "\n",
    "image, image_meta, gt_class_id, gt_bbox, gt_mask = mrcnn.model.load_image_gt(dataset, config, image_id)\n",
    "\n",
    "print(image.shape)\n",
    "\n",
    "info = dataset.image_info[image_id]\n",
    "print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id,\n",
    "                                       dataset.image_reference(image_id)))\n",
    "\n",
    "# Run object detection\n",
    "results = model_inference.detect([image], verbose=1)\n",
    "\n",
    "# Display results\n",
    "r = results[0]\n",
    "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], dataset.class_names, r['scores'], title=\"Predictions\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
